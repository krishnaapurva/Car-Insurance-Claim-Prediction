# Car-Insurance-Claim-Prediction
The "Car Insurance Claim Prediction" aims to predict if policyholders will file an insurance claim in the next six months by analyzing a comprehensive dataset. This insight will help insurance companies refine their risk assessment and pricing strategies. 

# Project Motivation
The "Car Insurance Claim Prediction" project is driven by the evolving landscape of data analytics and predictive modeling in the insurance sector, particularly car insurance. Analyzing a comprehensive dataset, the project aims to predict policyholders' likelihood of filing a claim within six months. This predictive insight will revolutionize risk assessment and pricing strategies, empowering insurance companies to manage risk in the industry proactively.
The primary objective is to craft a highly accurate predictive model using policyholder attributes. This model will facilitate data-informed decision-making, allowing insurance firms to pre-emptively address risks and optimize operational efficiency.

# DATA DESCRIPTION 
Data mining techniques have a wide range of applications across various domains. For our project, we have chosen to work on the problem of predicting car insurance claims. We have collected 43 input attributes such as policy tenure, age of the car, model, segment, fuel type, etc. The target variable is whether a claim is made, represented by the binary variable 'is_claim.’ This is a classification problem, and we have used four different algorithms - Logistic Regression, Decision Trees, Random Forests, and Neural Networks - to predict the loan status.
The dataset we have taken is from Kaggle, and it has over 43 input attributes that help us understand the Claim prediction. We have plotted several graphs as part of our exploratory data analysis to understand our data better.

# EXPLORATORY DATA ANALYSIS
During the exploratory data analysis (EDA) phase, we thoroughly examined the dataset, paying close attention to different aspects. We aimed to extract valuable insights from the data and ensure it was well-prepared for modeling purposes.  
**[1]**  Verifying the summary of the dataset structure to understand the data values.

**[2]**  Next, we verify that we have any NA or NULL values in the dataset.  

**[3]**  A pie chart is generated by the code to display the distribution of instances belonging to the 'No Claim' and 'Claim' categories. This pie chart helps to reveal the class imbalance in the target variable 'is_claim.' The legend and colors used in the chart accurately depict the two categories, emphasizing the necessity of addressing this imbalance while constructing the model to achieve better predictive accuracy.
The chart shows the percentage of No claims for car insurance and claims for car insurance.  
•	The Percentage of No claims for car insurance is 93.4%  
•	The percentage of claims for car insurance is 6.4%.  
![Pie chart](https://github.com/krishnaapurva/Car-Insurance-Claim-Prediction/assets/41700695/d8445aca-5817-4b73-8650-9a059e492481)


**[4]** The count plots showcasing the distribution of different categorical variables like 'area_cluster,' 'segment,' 'model,' 'fuel_type,' 'max_torque,' 'max_power,' and 'engine_type' concerning the 'No Claim' and 'Claim' classes. Each plot visualizes the count of occurrences for both classes, aiding in understanding the class distribution within these categorical features. These visualizations offer insights into potential correlations between categorical variables and the claim outcomes, providing a clear understanding of their impact on the target variable.  

![area_cluster](https://github.com/krishnaapurva/Car-Insurance-Claim-Prediction/assets/41700695/e3d5445a-38e9-4d40-baaa-bf526866c8da)

![segment](https://github.com/krishnaapurva/Car-Insurance-Claim-Prediction/assets/41700695/7836e176-963c-42c3-a6be-4a086ebfcfc5)

![model](https://github.com/krishnaapurva/Car-Insurance-Claim-Prediction/assets/41700695/da0c94f5-0d2e-4573-a6db-822523664a29)

![fuel_type](https://github.com/krishnaapurva/Car-Insurance-Claim-Prediction/assets/41700695/9a090d82-452e-4ecc-b947-180dd8ce7cd9)

![max_torque](https://github.com/krishnaapurva/Car-Insurance-Claim-Prediction/assets/41700695/5d28f828-98b2-4ac1-b8ba-c09b016024a5)

![max_power](https://github.com/krishnaapurva/Car-Insurance-Claim-Prediction/assets/41700695/0fcd079a-8d89-4a82-8d45-d9d2a5bc839f)

![engine_type](https://github.com/krishnaapurva/Car-Insurance-Claim-Prediction/assets/41700695/101152ce-d3c7-4b91-9130-2a7a18e357f1)


**[5]** As part of our data processing, we extract numerical values in Newton meters (Nm) and revolutions per minute (rpm) from the 'max_torque' data. After that, we calculate the ratio of torque to rpm and add a new column named 'torque_to_rpm_ratio' to the dataset to consolidate this information. Similarly, we are doing this for the ‘max_power’ data.  

**[6]** To handle binary categorical columns in the dataset 'df.train_filter', we first identified the columns prefixed with "is_" using a pattern-matching approach. After the identification process, we proceeded to convert the categorical values ("Yes" and "No") into numeric format by assigning 1 to "Yes" and 0 to "No" across all the identified 'is_' columns within the dataset.  

**[7]** The variable 'columns_to_convert' holds the names of all the 'is_' columns that require conversion from categorical binary values to numeric representations. This conversion ensures consistency in the dataset 'df.train_filter' format for any further analytical or modeling purposes.  

**[8]** We use the 'fastDummies' library to convert categorical data into a numerical format by generating dummy variables. We remove original categorical columns and exclude specific extra dummy variables to avoid overfitting and ensure a streamlined and effective dataset for analysis and modeling.  

**[9]** We standardize column names by replacing spaces, periods, and hyphens with underscores.  

**[10]** To train and evaluate our predictive model, we partitioned the dataset randomly into two subsets: training and validation. The training set comprised 60% of the data, while the validation set contained the remaining 40%. This approach ensured that the model was trained on a significant portion of the data while also allowing us to evaluate its performance on a separate subset.  

**[11]** To resolve the class imbalance issue in the training dataset, we use an oversampling technique that involves replicating instances of the minority class (where 'is_claim' equals 1) until the count of both classes is equal. This oversampling is performed through the ovun.sample() function available in the 'ROSE' package. Following this, we calculate the number of instances where 'is_claim' equals 1 in the balanced dataset. This helps in achieving a more balanced distribution of classes within the training data.  

**[12]** Presenting the distribution of claims and no-claims after performing oversampling.  

![after_oversampling](https://github.com/krishnaapurva/Car-Insurance-Claim-Prediction/assets/41700695/3339869d-a3ce-4741-b84e-4a44c845b707)








